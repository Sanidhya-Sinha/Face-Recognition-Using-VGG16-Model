{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "rows = 224\n",
    "cols = 224\n",
    "\n",
    "model = VGG16(weights = 'imagenet', include_top = False, input_shape = (rows, cols, 3))\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i) + \" \" + layer.__class__.__name__, layer.trainable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def addlayer(bottom_model, num_classes):\n",
    "    \"\"\"creates the head of the model that will bw placed on top of the bottom layers\"\"\"\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x262ea949208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f3205708>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f32057c8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x262f3265608>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f3265bc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f3276948>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x262f32765c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f327a408>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f32856c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f3286288>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x262f3291948>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f3295688>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f329ca88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f32a2108>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x262f32afc88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f32aae88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f32b1148>,\n",
       " <keras.layers.convolutional.Conv2D at 0x262f32be208>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x262f32c2b88>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 16,815,426\n",
      "Trainable params: 2,100,738\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "FC_Head = addlayer(model, num_classes)\n",
    "modelnew = Model(inputs=model.input, outputs=FC_Head)\n",
    "print(modelnew.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'training/'\n",
    "validation_data_dir = 'validation/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(rows, cols),\n",
    "                                                    batch_size=train_batchsize,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                    target_size=(rows, cols),\n",
    "                                                    batch_size=val_batchsize,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "74/74 [==============================] - 395s 5s/step - loss: 0.6781 - accuracy: 0.7049 - val_loss: 0.5285 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52846, saving model to face_recog_vgg.h5\n",
      "Epoch 2/4\n",
      "74/74 [==============================] - 413s 6s/step - loss: 0.2240 - accuracy: 0.9341 - val_loss: 0.0013 - val_accuracy: 0.9600\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52846 to 0.00127, saving model to face_recog_vgg.h5\n",
      "Epoch 3/4\n",
      "74/74 [==============================] - 380s 5s/step - loss: 0.1722 - accuracy: 0.9440 - val_loss: 2.3865 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00127\n",
      "Epoch 4/4\n",
      "74/74 [==============================] - 395s 5s/step - loss: 0.1697 - accuracy: 0.9488 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00127\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"face_recog_vgg.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only = True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor= 'val_loss', min_delta = 0, patience = 3, verbose = 1, restore_best_weights = True)\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "modelnew.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001),metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples=1190\n",
    "nb_validation_samples=170\n",
    "epochs=4\n",
    "batch_size=16\n",
    "\n",
    "history = modelnew.fit_generator(train_generator,\n",
    "                                 steps_per_epoch=nb_train_samples // batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 callbacks=callbacks,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 validation_steps=nb_validation_samples // batch_size)\n",
    "modelnew.save(\"face_recog_vgg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
